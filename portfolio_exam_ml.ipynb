{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# «Portfolio-Exam Part I» MADS-ML\n",
    "\n",
    "This is the ﬁrst part of the portfolio-exam for the Data Science course MADS-ML (Machine Learning). <br>\n",
    "This part of the exam is homework. Student’s are allowed to exchange ideas. However, this is NOT a <br>\n",
    "teamwork exercise. Every student must derive and write up their own solutions in their own words <br>\n",
    "and programming style. <br>\n",
    "To complete this ﬁrst part of the exam, <br>\n",
    "• solve ALL the following tasks (two pages!), <br>\n",
    "• create a commented Jupyter Notebook for the code as well as for your textual answers, and <br>\n",
    "• upload the ﬁle to Moodle before 23:59 o’clock (German time) December 12th, 2021. <br>\n",
    "Note: In the Notebook, please state clearly which task a piece of code or text belongs to. Some of the <br>\n",
    "tasks are not strictly separable, e.g. setting up the cross validation and using it on the algorithms. <br>\n",
    "In these cases, just indicate in the notebook, which tasks the respective piece of code addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1. (Random Forest, 20 points)\n",
    "Research: Read up on the algorithm Random Forest [1]. You may select a reliable source of your\n",
    "choice for that purpose.  <br> You should be able to explain the basic idea of the algorithm and understand\n",
    "the application of the implementation in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 (10 points) Describe the relation between Random Forests and Decision Trees (for classiﬁcation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest algorithm is part of the ensemble methods. Ensemble learning describes a process that uses a set of classifiers and their predictions are aggregated to find the best result. Random Forest uses a set of decision trees as classifier. The decision trees in the Random Forest classifier are using not the full training data, instead there use a subset. This subsets are created to the techniquie of Bootstrap Aggregation (Bagging). The Bagging method takes a random sample of the data with replacement and this are then the subsets for every decision tree. In this case means replacement that the individual data point can be choosen more than one time. The size of the random sample is controlled in sklearn thorugh the max_samples parameter. The dafault value is the size of the full training set. If we sampling from the existing dataset the chance that the subsets of the decision trees are all very similar and contain the same features is high. To avoid this issues the Random Forest algorithm uses a parmeter to do \"random splitting\". In sklearn this parameter is max_feature. This parameter defines the amount of feature to condsider for the best split. In classification the default value in sklearn equals max_feature the square root of all avavailable features. This has been empirical shown the best results. In this way each decision tree isn't perfect designed but the amount of different decision trees are more various and not so much correlated. In comparison to decision trees all feature are considered for the best split. <br>\n",
    "The last step of the Random Forest algorithm is the that each decision tree predict a class and the class with most votes is the result. The prediction is the average of all decision trees. The main differnces between dicision trees and Random forest are the ensemble method and the Bootstrap Aggregation. Instead of using the original dataset, the Random forest classifier uses random subsets for the amount of decision trees in the algorithm. The way to do predictions is also different because the random forest algotihm takes result which has the most votes from decision trees, instead using the best score of one decision tree, like a normal decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. (6 points) Compare the Random Forest and the Decision Tree classiﬁer in sklearn by discussing  <br> the parameters n_estimators, criterion, and max_depth. Explain what the parameters control and why <br>  they are applicable to both algorithms or just the one.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter criterion decribes the function how to split the decision tree. Like we discussed in the lecture we can choose between the default paramter gini or entropie. The random forest and the decision tree using both this parameter because they need to to know how to split their decision tree. The random forest exists of multiple decision tree that's the reason why it needs this parameter. <br> \n",
    "The paramter max_deph decribes the depth of a decision tree. The default value is none that means thats the leaves will be expand until they are pure or until all leaves contain less than the parameter min_samples_split. Both algorithm needs this parameter because the decision tree needs this infortmation and the random forest exists out of decision trees. <br> \n",
    "Only the parameter n_estimators is used only in the Random forest algorithm. This parameter decribes the amount of decision trees which are used in the Random Forest algorithm. The Decsion tree doesn't need this information because it only one decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 (4 points) Compare the two algorithms with respect to their application:   <br> Which are immediate advantages and disadvantages of Random Forest over Decision Trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are easy to interpret and good to visulazie. The decisions of random forest are not so easy to interpret when there are contains 100 of decision trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. (Data Acquisition, 10 Points)\n",
    "Find and download the dataset “Online Shoppers Purchasing Intention” [2]. Use the dataset to tackle\n",
    "to following question: Given a user’s browsing behavior during a session in a web system as well as  <br>\n",
    "some other features of that session, predict whether the user will buy something (indicated in the\n",
    "column revenue by true or false). Load the dataset in python and answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. (5 points) How many numerical features can we use for predicting whether revenue is true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing, tree\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "import sklearn.metrics as ms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"online_shoppers_intention.csv\", sep= \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 10 numerical and 8 catogorical features. Following features are numerical: Administrative_Duration, Informational_Duration, ProductRelated_Duration, BounceRates, ExitRates, PageValues, SpecialDay,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 (5 points) Describe and comment on the class distribution in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 12.330 instances. The revenue false have 10.422 instances and revenue true have 1908 instances. If revenue equals true then this instances ends with shopping, if revenue was false then this instances without buying something. The distribution is imbalanced that can lead to high accuracy even we miss all elements of the small classes. The problem is when we splitt the dataset that the subsets have a different distribution. The solution is Stratifcation where we enforce the same class distribtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10422\n",
      "The dataset contains:12330 samples of online shopping. The revenue negative is 84.53% and the revenue positive is 15.47%.\n"
     ]
    }
   ],
   "source": [
    "distribution = df[\"Revenue\"].value_counts()\n",
    "print(distribution[0])\n",
    "distribution[0].dtype\n",
    "print(\"The dataset contains:\"+ str(df.shape[0]) + \" samples of online shopping. The revenue negative is \"+ str(round(distribution[0]/df.shape[0]*100,2)) + \"% and the revenue positive is \"+ str(round(distribution[1]/df.shape[0]*100,2)) + \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3. (Machine Learning Setup – 15 points) <br>\n",
    "Setup a machine learning experiment by <br>\n",
    "\n",
    "• splitting the target attribute from the data, converting it into a form suitable for sklearn <br>\n",
    "classiﬁers and preparing the numerical attributes as features, <br>\n",
    "\n",
    "• selecting 30% of the data as test data (choose random seed 42), <br>\n",
    "\n",
    "• scaling the data such that the features have similar average and standard distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Revenue\"]\n",
    "X = df[[\"Administrative_Duration\", \"Informational_Duration\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_sc = scaler1.transform(X_train)\n",
    "scaler2 = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_sc = scaler2.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split target Revenue in y, add numerical feature in x, divide dataseit in train and test data, and use the standardscaler to scale X_train to have similar averages and standard distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4. (Cross Validation – 17 points) <br>\n",
    "Use a combination of the classes GridSearchCVand RepeatedStratifiedKFoldto setup <br>\n",
    "a cross validation procedure for hyper parameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 (5 points) Create a cross validation setting in which the data is split into 10 folds, where all experiments are repeated 10 times, and where algorithms are evaluated using balanced accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_setting(X,y,model, params):    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n",
    "    clf = GridSearchCV(model, params, scoring='balanced_accuracy', cv=cv)\n",
    "    search = clf.fit(X,y)\n",
    "    return search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 (2 points) Which dataset is used in the grid search cross validation (training data, test data, or full dataset)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the full dataset and fold it into 10 subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 (3 points) Explain, what happens to that dataset during the grid search procedure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gridsearch takes the model, the hyperparameter(params), the scoring type, the splitted dataset(cv) as input. The dataset is devided into 10 subsets. The GridSearch takes all inputs and builds a grid of it with all information. When we run the command fit. It runs all combinations of the grid and the command best_params_ shows us the hyperparmeter with the best balanced accurancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. (5 points) What is the difference between using RepeatedStratifiedKFold and the default cross validation in GridSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 (2 points) Explain the purpose that justiﬁes repeating experiments on the same dataset and on different folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of doing the experiment just ones can lead to outliers and different results. Repeated experiments take every result and calculate the mean that leads to more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5. (Evaluation of Classiﬁers – 10 points)\n",
    "Use the above cross validation setup to optimize and compare tree based learners. Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (5 points) Decision Trees with the Gini criterion and test parameters 2 through 14 for max_depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score for a Decision tree is with max depth of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "max_depth_range = list(range(2,15))\n",
    "hyperparameter = {\"max_depth\": max_depth_range}\n",
    "score = cross_validate_setting(X,y,clf,hyperparameter)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 (5 points) Random Forests with 1, 10, or 100 trees and 2,3,5, or 10 for max_depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score for a Randomforest is with max depth of 10 and 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "hyperparameter = {\"max_depth\": [2,3,5,10], \"n_estimators\": [1,10,100]}\n",
    "score = cross_validate_setting(X,y,clf,hyperparameter)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6. (Oversampling – 8 points)\n",
    "Use oversampling to create a balanced training dataset. Look at the class\n",
    "imblearn.over_sampling.RandomOverSamplerfor that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 (2 points) What does the above class do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class oversample the minority class by picking samples at random with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 (3 points) Why is oversampling only applied to the training dataset (not to the test data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intent is to create a better model. Otherwise the evaluation of test data is showing wrong results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 (3 points) Optimize Random Forest with the same search grid as before, but trained on a balanced training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train_sc, y_train)\n",
    "clf = RandomForestClassifier()\n",
    "hyperparameter = {\"max_depth\": [2,3,5,10], \"n_estimators\": [1,10,100]}\n",
    "score = cross_validate_setting(X_res,y_res,clf,hyperparameter)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({False: 7298, True: 7298})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both cases (positive, ngeative) are balenced. The hyperparamter number of trees has change to 10 but the depth is the same like without a balanced data set (max_depth = 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7. (Interpretation – 20 points)\n",
    "Evaluate the resulting three algorithms of the three above cross validation experiments (Decision\n",
    "Tree and two versions of Random Forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 (2 points) Prepare a data frame in which the evaluation results of algorithms can be stored with columns for the algorithm, accuracy, balanced accuracy, confusion matrix and the best hyperparameters of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame({'algorithm':[], 'accuracy':[],'balanced accuracy':[], 'confusion matrix':[],'best hyperparameters':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 (2 points) On which dataset should the performance of algorithms (with already optimized hyper parameters) be compared (training data, test data, full data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance needs to be compared with test data. Otherwise we could have overfitting and the algorithms are only working for the optimized training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 (6 points) For each algorithm report the best choice of hyperparameters found using the above cross validations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "max_depth_range = list(range(2,15))\n",
    "hyperparameter = {\"max_depth\": max_depth_range}\n",
    "score_decision_tree = cross_validate_setting(X,y,clf,hyperparameter)\n",
    "print(score_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = evaluation_df.append(pd.DataFrame({'algorithm':['Decision tree'], 'best hyperparameters':[score_decision_tree]}),ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "hyperparameter = {\"max_depth\": [2,3,5,10], \"n_estimators\": [1,10,100]}\n",
    "score_random_forest = cross_validate_setting(X,y,clf,hyperparameter)\n",
    "print(score_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = evaluation_df.append(pd.DataFrame({'algorithm':['RandomForest'], 'best hyperparameters':[score_random_forest]}),ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balanced RandomForest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train_sc, y_train)\n",
    "clf = RandomForestClassifier()\n",
    "hyperparameter = {\"max_depth\": [2,3,5,10], \"n_estimators\": [1,10,100]}\n",
    "score_balanced_random_forest = cross_validate_setting(X_res,y_res,clf,hyperparameter)\n",
    "print(score_balanced_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add best hyperparamters in evaluation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = evaluation_df.append(pd.DataFrame({'algorithm':['balanced RandomForest'], 'best hyperparameters':[score_balanced_random_forest]}),ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>confusion matrix</th>\n",
       "      <th>best hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               algorithm  accuracy  balanced accuracy  confusion matrix  \\\n",
       "0          Decision tree       NaN                NaN               NaN   \n",
       "1           RandomForest       NaN                NaN               NaN   \n",
       "2  balanced RandomForest       NaN                NaN               NaN   \n",
       "\n",
       "                     best hyperparameters  \n",
       "0                        {'max_depth': 3}  \n",
       "1  {'max_depth': 10, 'n_estimators': 100}  \n",
       "2  {'max_depth': 10, 'n_estimators': 100}  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 (6 points) Compare three classiﬁers regarding both accuracy and balanced accuracy. Recommend a setting for use in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General function to create the accuracy score and a function to calculate the balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_score(model,x_train,y_train,x_test,y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    print(accuracy_score(y_test, y_test_pred))\n",
    "    return accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_balanced_accuracy_score(model,x_train,y_train,x_test,y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    print(balanced_accuracy_score(y_test, y_test_pred))\n",
    "    return balanced_accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8834820221681535\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini', random_state=1, max_depth=3)\n",
    "evaluation_df.iloc[0,1] = calc_accuracy_score(model,X_train_sc, y_train, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7515108834827144\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini', random_state=1, max_depth=3)\n",
    "evaluation_df.iloc[0,2] = calc_balanced_accuracy_score(model,X_train_sc, y_train, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8932143822654771\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='gini', random_state=1, max_depth=10,n_estimators=100)\n",
    "evaluation_df.iloc[1,1] = calc_accuracy_score(model,X_train_sc, y_train, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7459205032566943\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='gini', random_state=1, max_depth=10,n_estimators=100)\n",
    "evaluation_df.iloc[1,2] = calc_balanced_accuracy_score(model,X_train_sc, y_train, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balanced random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8759124087591241\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='gini', random_state=1, max_depth=10,n_estimators=100)\n",
    "evaluation_df.iloc[2,1] = calc_accuracy_score(model,X_res, y_res, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8392662695540833\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='gini', random_state=1, max_depth=10,n_estimators=100)\n",
    "evaluation_df.iloc[2,2] = calc_balanced_accuracy_score(model,X_res, y_res, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add values into evualtion dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>confusion matrix</th>\n",
       "      <th>best hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.883482</td>\n",
       "      <td>0.751511</td>\n",
       "      <td>[[2946, 178], [253, 322]]</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.893214</td>\n",
       "      <td>0.745921</td>\n",
       "      <td>[[2998, 126], [269, 306]]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced RandomForest</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.839266</td>\n",
       "      <td>[[2788, 336], [123, 452]]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               algorithm  accuracy  balanced accuracy  \\\n",
       "0          Decision tree  0.883482           0.751511   \n",
       "1           RandomForest  0.893214           0.745921   \n",
       "2  balanced RandomForest  0.875912           0.839266   \n",
       "\n",
       "            confusion matrix                    best hyperparameters  \n",
       "0  [[2946, 178], [253, 322]]                        {'max_depth': 3}  \n",
       "1  [[2998, 126], [269, 306]]  {'max_depth': 10, 'n_estimators': 100}  \n",
       "2  [[2788, 336], [123, 452]]  {'max_depth': 10, 'n_estimators': 100}  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 (4 points) Explain differences in the values of the two quality measures using confusion matrixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(y_test,y_pred,y_test_2,y_pred_2):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "        ms.ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=axes[0])\n",
    "        ms.ConfusionMatrixDisplay.from_predictions(y_test_2, y_pred_2, ax=axes[1])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add confusion matrix to evaluation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2946  178]\n",
      " [ 253  322]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini', random_state=1, max_depth=3)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "y_test_pred = clf.predict(X_test_sc)\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "plot_confusion(y_test,y_test_pred)\n",
    "evaluation_df.iloc[0,3] = [confusion_matrix(y_test, y_test_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2998  126]\n",
      " [ 269  306]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='gini', random_state=1, max_depth=10,n_estimators=100)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "y_test_pred = clf.predict(X_test_sc)\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "evaluation_df.iloc[1,3] = [confusion_matrix(y_test, y_test_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2788  336]\n",
      " [ 123  452]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='gini', random_state=1, max_depth=10,n_estimators=100)\n",
    "clf.fit(X_res, y_res)\n",
    "y_test_pred = clf.predict(X_test_sc)\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "evaluation_df.iloc[2,3] = [confusion_matrix(y_test, y_test_pred)]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c0d60a8dc4e599671dda9aae91492f37892c3bc3698cd654f77b9c4642bb760"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
